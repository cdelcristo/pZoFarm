{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words\n",
    "   \n",
    "1. Representation of text that describes the occuerence of words within a text \n",
    "2. Any information about order or structure is discarded\n",
    "3. Represent document x as set of(wi,fi)\n",
    "\n",
    "We convert text to a numerical represenattion called a feature vector . A feature vector can be as simple as a list of numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements=[{'city':'Dubai','temperature':33.},\n",
    "              {'city':'London','temperature':12.},\n",
    "              {'city':'San Francsisco','temperature':18.},{'city':'Toronto','temperature':14.},]\n",
    "#Transforms list of feature-value \n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec=DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   0.   0.   0.  33.]\n",
      " [  0.   1.   0.   0.  12.]\n",
      " [  0.   0.   1.   0.  18.]\n",
      " [  0.   0.   0.   1.  14.]]\n"
     ]
    }
   ],
   "source": [
    "print(vec.fit_transform(measurements).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['city=Dubai', 'city=London', 'city=San Francsisco', 'city=Toronto', 'temperature']\n"
     ]
    }
   ],
   "source": [
    "print(vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Methods in DictVectorizer\n",
    "1. fit(X[,y])\tLearn a list of feature name -> indices mappings.\n",
    "2. fit_transform(X[,y])\tLearn a list of feature name -> indices mappings and transform X.\n",
    "3. get_feature_names()\tReturns a list of feature names, ordered by their indices.\n",
    "4. get_params([deep])\tGet parameters for this estimator.\n",
    "5. inverse_transform(X[, dict_type])\tTransform array or sparse matrix X back to feature mappings.\n",
    "6. restrict(support[, indices])\tRestrict the features to those in support using feature selection.\n",
    "7. set_params(**params)\tSet the parameters of this estimator.\n",
    "8. transform(X)\tTransform feature->value dicts to array or sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert a collection of text documents to a matrix of token counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[\n",
    "    'Mcmaster BDA 102 is an interesting course',\n",
    "    'I can not wait for Saturday!',\n",
    "    'Mcmaster students shall use BDA 102 to successfully combat Skynet',\n",
    "    'I wish i was as strong as thanos',\n",
    "    'Sarah Conor is out of reach.'\n",
    "]\n",
    "#print(type(corpus))\n",
    "#print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorizer.fit_transform(corpus).todense())\n",
    "#todense converts to a spare matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Methods in CountVectorizer\n",
    "1. build_analyzer()\tReturn a callable that handles preprocessing and tokenization\n",
    "2. build_preprocessor()\tReturn a function to preprocess the text before tokenization\n",
    "3. build_tokenizer()\tReturn a function that splits a string into a sequence of tokens\n",
    "4. decode(doc)\tDecode the input into a string of unicode symbols\n",
    "5. fit(raw_documents[, y])\tLearn a vocabulary dictionary of all tokens in the raw documents.\n",
    "6. fit_transform(raw_documents[, y])\tLearn the vocabulary dictionary and return term-document matrix.\n",
    "7. get_feature_names()\tArray mapping from feature integer indices to feature name\n",
    "8. get_params([deep])\tGet parameters for this estimator.\n",
    "9. get_stop_words()\tBuild or fetch the effective stop words list\n",
    "10. inverse_transform(X)\tReturn terms per document with nonzero entries in X.\n",
    "11. set_params(**params)\tSet the parameters of this estimator.\n",
    "12. transform(raw_documents)\tTransform documents to document-term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Application\n",
    "train_set=(\"The sky is blue,\", \"The sun is bright.\")\n",
    "test_set=(\" The sun in the sky is bright.\",\n",
    "          \"We can see the shining sun ,the bright sun.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer =CountVectorizer(stop_words='english')\n",
    "vectorizer.fit_transform(train_set)\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorizer.transform(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASS ACTIVITY\n",
    "1. go to this avenue select the welcome message from BDA 102 and 101 or BDA 104 OR BDA 103\n",
    "\n",
    "2. create a list with  variables containing each text message \n",
    "\n",
    "3. Build vocubalary then print array from the list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz 2\n",
    "\n",
    "1. Sum the two rows and build a frequency table\n",
    "\n",
    "2. check type and see whether it is dataframe \n",
    "\n",
    "3. if not dataframe,convert it to a dataframe.\n",
    "\n",
    "4. To this dataframe give a column name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
